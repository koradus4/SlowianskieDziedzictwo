"""
ModuÅ‚ TTS - wspiera lokalny Piper i Google Cloud TTS
"""

import subprocess
import os
from pathlib import Path
import uuid
import re
import wave
import tempfile
import logging

# Importuj skonfigurowany logger z game_logger (jeÅ›li dostÄ™pny)
try:
    from game_logger import logger
except ImportError:
    # Fallback jeÅ›li game_logger nie istnieje
    logger = logging.getLogger("SlowianskieDziedzictwo")

# SprÃ³buj zaimportowaÄ‡ Google Cloud Storage i TTS
try:
    from google.cloud import storage
    HAS_CLOUD_STORAGE = True
except ImportError:
    HAS_CLOUD_STORAGE = False

try:
    from google.cloud import texttospeech
    HAS_CLOUD_TTS = True
except ImportError:
    HAS_CLOUD_TTS = False

try:
    from pydub import AudioSegment
    HAS_PYDUB = True
except ImportError:
    HAS_PYDUB = False


class TTSEngine:
    """Silnik TTS - Piper (lokalnie) lub Google Cloud TTS (produkcja)"""
    
    def __init__(self, podcast_dir: Path):
        self.podcast_dir = Path(podcast_dir)
        self.piper_exe = self.podcast_dir / "piper" / "piper.exe"
        self.espeak_data = self.podcast_dir / "piper" / "espeak-ng-data"
        
        # ÅšcieÅ¼ka do gÅ‚osÃ³w lokalnych (w katalogu projektu)
        project_root = Path(__file__).parent
        self.voices_dir = project_root / "glosy_lokalnie"
        
        # ÅšcieÅ¼ki do gÅ‚osÃ³w (Piper lokalnie)
        self.glosy = {
            "jarvis": self.voices_dir / "jarvis" / "pl_PL-jarvis_wg_glos-medium.onnx",
            "meski": self.voices_dir / "meski" / "pl_PL-meski_wg_glos-medium.onnx",
            "zenski": self.voices_dir / "zenski" / "pl_PL-zenski_wg_glos-medium.onnx",
            "justyna": self.voices_dir / "justyna" / "pl_PL-justyna_wg_glos-medium.onnx",
            "darkman": self.voices_dir / "darkman" / "pl_PL-darkman-medium.onnx"
        }
        
        # Cloud Storage
        self.bucket_name = os.environ.get('GCS_BUCKET_NAME')
        self.use_cloud = self.bucket_name and HAS_CLOUD_STORAGE
        
        # Cloud TTS (Google)
        self.use_cloud_tts = HAS_CLOUD_TTS and self.use_cloud
        if self.use_cloud_tts:
            self.tts_client = texttospeech.TextToSpeechClient()
            print(f"ðŸ”Š UÅ¼ywam Google Cloud Text-to-Speech")
        
        if self.use_cloud:
            self.storage_client = storage.Client()
            self.bucket = self.storage_client.bucket(self.bucket_name)
            print(f"â˜ï¸ UÅ¼ywam Cloud Storage: gs://{self.bucket_name}")
        else:
            # Lokalny katalog na audio
            self.audio_dir = Path(__file__).parent / "audio"
            self.audio_dir.mkdir(exist_ok=True)
            print(f"ðŸ“ UÅ¼ywam lokalnego audio: {self.audio_dir}")
    
    def _zapisz_audio_cloud(self, local_path: Path) -> str:
        """Zapisuje plik audio do Cloud Storage i zwraca publiczny URL"""
        if not self.use_cloud:
            return None
        
        blob_name = f"audio/{local_path.name}"
        blob = self.bucket.blob(blob_name)
        blob.upload_from_filename(str(local_path))
        
        # ZwrÃ³Ä‡ publiczny URL (wymaga ustawienia bucket jako public)
        return f"https://storage.googleapis.com/{self.bucket_name}/{blob_name}"
    
    def syntezuj(self, tekst: str, glos: str = "jarvis") -> str:
        """Syntezuje tekst do pliku audio i zwraca URL (cloud) lub Path (lokalnie)"""
        
        # Cloud TTS (Google - produkcja)
        if self.use_cloud_tts:
            return self._syntezuj_google_tts(tekst)
        
        # Piper lokalnie
        if not self.piper_exe.exists():
            print(f"Brak piper.exe: {self.piper_exe}")
            return None
            
        model_path = self.glosy.get(glos)
        if not model_path or not model_path.exists():
            print(f"Brak modelu gÅ‚osu: {glos}")
            return None
        
        # Lokalny plik wyjÅ›ciowy
        output_file = self.audio_dir / f"{uuid.uuid4().hex}.wav"
        
        try:
            cmd = [
                str(self.piper_exe),
                "--model", str(model_path),
                "--data-dir", str(self.espeak_data),
                "--output_file", str(output_file)
            ]
            
            process = subprocess.Popen(
                cmd,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
            )
            
            stdout, stderr = process.communicate(input=tekst.encode('utf-8'), timeout=60)
            
            if process.returncode == 0 and output_file.exists():
                return str(output_file)
            else:
                print(f"BÅ‚Ä…d TTS: {stderr.decode('utf-8', errors='ignore')[:100]}")
                return None
                
        except Exception as e:
            print(f"BÅ‚Ä…d syntezy: {e}")
            return None
    
    def _syntezuj_google_tts(self, tekst: str, voice_name: str = "pl-PL-Wavenet-B", pitch: float = 0.0) -> str:
        """Generuje audio przez Google Cloud TTS i zwraca publiczny URL"""
        print(f"ðŸŽ™ï¸ _syntezuj_google_tts: voice_name='{voice_name}', pitch={pitch}, tekst_len={len(tekst)}")
        logger.info(f"ðŸŽ™ï¸ _syntezuj_google_tts: voice_name='{voice_name}', pitch={pitch}, tekst_len={len(tekst)}")
        try:
            # Przygotuj Å¼Ä…danie
            synthesis_input = texttospeech.SynthesisInput(text=tekst)
            
            # Wybierz gÅ‚os polski z dostosowanym pitch
            # Google Cloud TTS - polskie gÅ‚osy Wavenet:
            # A (FEMALE wyrazista), B (MALE gÅ‚Ä™boki), C (MALE spokojny), D (FEMALE), E (FEMALE delikatna)
            gender = texttospeech.SsmlVoiceGender.MALE if "B" in voice_name or "C" in voice_name else texttospeech.SsmlVoiceGender.FEMALE
            voice = texttospeech.VoiceSelectionParams(
                language_code="pl-PL",
                name=voice_name,
                ssml_gender=gender
            )
            
            # Konfiguracja audio z custom pitch
            audio_config = texttospeech.AudioConfig(
                audio_encoding=texttospeech.AudioEncoding.MP3,
                speaking_rate=1.0,
                pitch=pitch  # UÅ¼ywamy pitch z mapy
            )
            
            # WywoÅ‚aj API
            response = self.tts_client.synthesize_speech(
                input=synthesis_input,
                voice=voice,
                audio_config=audio_config
            )
            
            # ZwrÃ³Ä‡ raw bytes (do sklejania)
            return response.audio_content
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d Google Cloud TTS: {e}")
            return None
    
    def _syntezuj_google_tts_multi(self, segments: list) -> str:
        """Generuje wielogÅ‚osowe audio i zwraca URL"""
        if not HAS_PYDUB:
            print("âš ï¸ Brak pydub - uÅ¼ywam pojedynczego gÅ‚osu")
            tekst_pelny = " ".join([seg[1] for seg in segments])
            return self._syntezuj_google_tts_single(tekst_pelny)
        
        try:
            audio_parts = []
            
            # Mapowanie gÅ‚osÃ³w - Google Cloud ma 5 polskich Wavenet gÅ‚osÃ³w:
            # A (FEMALE), B (MALE), C (MALE), D (FEMALE), E (FEMALE)
            # UÅ¼ywam pitch do rÃ³Å¼nicowania narrator vs NPC mÄ™ski (oba B)
            voice_map = {
                "narrator": ("pl-PL-Wavenet-B", -2.0),   # MÄ™ski gÅ‚Ä™boki
                "gracz_m": ("pl-PL-Wavenet-C", 0.0),     # MÄ™ski spokojny
                "gracz_k": ("pl-PL-Wavenet-E", 1.5),     # Kobieta delikatna
                "npc_m": ("pl-PL-Wavenet-B", 1.0),       # MÄ™ski wyÅ¼ej (pitch rÃ³Å¼ni od narratora)
                "npc_k": ("pl-PL-Wavenet-A", 2.0)        # Kobieta wyrazista
            }
            
            # Generuj audio dla kaÅ¼dego segmentu
            for voice_type, tekst in segments:
                if not tekst.strip():
                    continue
                
                voice_name, pitch = voice_map.get(voice_type, ("pl-PL-Wavenet-B", -2.0))
                print(f"ðŸŽµ Segment: voice_type='{voice_type}' â†’ voice_name='{voice_name}', pitch={pitch}, tekst_len={len(tekst)}")
                logger.info(f"ðŸŽµ Segment: voice_type='{voice_type}' â†’ voice_name='{voice_name}', pitch={pitch}, tekst_len={len(tekst)}")
                audio_bytes = self._syntezuj_google_tts(tekst, voice_name, pitch)
                
                if audio_bytes:
                    # Konwertuj bytes na AudioSegment
                    temp_path = Path(tempfile.gettempdir()) / f"{uuid.uuid4().hex}.mp3"
                    temp_path.write_bytes(audio_bytes)
                    segment = AudioSegment.from_mp3(str(temp_path))
                    audio_parts.append(segment)
                    temp_path.unlink()
            
            if not audio_parts:
                return None
            
            # Sklej wszystkie segmenty
            combined = sum(audio_parts)
            
            # Zapisz do pliku
            output_path = Path(tempfile.gettempdir()) / f"{uuid.uuid4().hex}.mp3"
            combined.export(str(output_path), format="mp3")
            
            # Uploaduj do Cloud Storage
            blob_name = f"audio/{output_path.name}"
            blob = self.bucket.blob(blob_name)
            blob.upload_from_filename(str(output_path))
            
            # UsuÅ„ tymczasowy plik
            output_path.unlink()
            
            # ZwrÃ³Ä‡ publiczny URL
            return f"https://storage.googleapis.com/{self.bucket_name}/{blob_name}"
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d wielogÅ‚osowego TTS: {e}")
            return None
    
    def _syntezuj_google_tts_single(self, tekst: str) -> str:
        """Pojedynczy gÅ‚os (fallback) - zwraca URL"""
        try:
            audio_bytes = self._syntezuj_google_tts(tekst, "pl-PL-Wavenet-B")
            if not audio_bytes:
                return None
            
            # Zapisz do tymczasowego pliku
            temp_file = Path(tempfile.gettempdir()) / f"{uuid.uuid4().hex}.mp3"
            temp_file.write_bytes(audio_bytes)
            
            # Uploaduj do Cloud Storage
            blob_name = f"audio/{temp_file.name}"
            blob = self.bucket.blob(blob_name)
            blob.upload_from_filename(str(temp_file))
            
            # UsuÅ„ tymczasowy plik
            temp_file.unlink()
            
            # ZwrÃ³Ä‡ publiczny URL
            return f"https://storage.googleapis.com/{self.bucket_name}/{blob_name}"
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d Google Cloud TTS: {e}")
            return None
    
    def dostepne_glosy(self) -> list:
        """Zwraca listÄ™ dostÄ™pnych gÅ‚osÃ³w"""
        return [g for g, p in self.glosy.items() if p.exists()]
    
    def syntezuj_multi_voice(self, tekst: str, plec_gracza: str = "mezczyzna") -> str:
        """
        Syntezuje tekst z wieloma gÅ‚osami (Cloud TTS) lub pojedynczym (Piper)
        VERSION: 2025-12-18 22:45 - Multi-voice fixed
        """
        print(f"ðŸŽ¤ syntezuj_multi_voice: use_cloud_tts={self.use_cloud_tts}, tekst_len={len(tekst)}")
        logger.info(f"ðŸŽ¤ syntezuj_multi_voice: use_cloud_tts={self.use_cloud_tts}, tekst_len={len(tekst)}")
        
        # Cloud TTS - wielogÅ‚osowa synteza
        if self.use_cloud_tts:
            segments = self._parsuj_dialogi_cloud(tekst, plec_gracza)
            if segments:
                return self._syntezuj_google_tts_multi(segments)
            else:
                # Fallback - pojedynczy gÅ‚os
                tekst_czysty = re.sub(r'\*\*[^:]+:\*\*\s*', '', tekst)
                return self._syntezuj_google_tts_single(tekst_czysty)
        
        # Piper lokalnie - wielogÅ‚osowa synteza (stary kod)
        print("ðŸŽ¤ UÅ¼ywam Piper lokalnie")
        logger.info("ðŸŽ¤ UÅ¼ywam Piper lokalnie")
        segments = self._parsuj_dialogi(tekst, plec_gracza)
        
        print(f"ðŸŽ¤ segments={len(segments)}")
        logger.info(f"ðŸŽ¤ segments={len(segments)}")
        
        if not segments:
            print("ðŸŽ¤ Brak segmentÃ³w, uÅ¼ywam jarvis fallback")
            logger.info("ðŸŽ¤ Brak segmentÃ³w, uÅ¼ywam jarvis fallback")
            return self.syntezuj(tekst, "jarvis")
        
        audio_files = []
        for speaker, text in segments:
            if text.strip():
                print(f"ðŸŽ¤ SyntetyzujÄ™: speaker={speaker}, len={len(text)}")
                logger.info(f"ðŸŽ¤ SyntetyzujÄ™: speaker={speaker}, len={len(text)}")
                audio_path = self.syntezuj(text, speaker)
                print(f"ðŸŽ¤ Rezultat: {audio_path}")
                logger.info(f"ðŸŽ¤ Rezultat: {audio_path}")
                if audio_path:
                    audio_files.append(Path(audio_path))
        
        print(f"ðŸŽ¤ audio_files={len(audio_files)}")
        logger.info(f"ðŸŽ¤ audio_files={len(audio_files)}")
        
        if not audio_files:
            print("ðŸŽ¤ BRAK audio_files - zwracam None!")
            logger.warning("ðŸŽ¤ BRAK audio_files - zwracam None!")
            return None
        
        if len(audio_files) == 1:
            result = str(audio_files[0])
            print(f"ðŸŽ¤ Zwracam pojedynczy plik: {result}")
            logger.info(f"ðŸŽ¤ Zwracam pojedynczy plik: {result}")
            return result
        
        result = str(self._sklej_audio(audio_files))
        print(f"ðŸŽ¤ Zwracam sklejone audio: {result}")
        logger.info(f"ðŸŽ¤ Zwracam sklejone audio: {result}")
        return result
    
    def _parsuj_dialogi_cloud(self, tekst: str, plec_gracza: str = "mezczyzna") -> list:
        """
        Parsuje tekst dla Cloud TTS i zwraca listÄ™ (typ_gÅ‚osu, tekst).
        Format: MÃ³wca: tekst (gwiazdki ** sÄ… juÅ¼ usuniÄ™te przez game_master)
        Narrator: â†’ narrator
        Gracz: â†’ gracz_m (mÄ™Å¼czyzna) lub gracz_k (kobieta)
        NPC [M]: â†’ npc_m
        NPC [K]: â†’ npc_k
        """
        segments = []
        
        logger.info(f"ðŸ” CLOUD TTS _parsuj_dialogi_cloud: zaczynamy parsowanie...")
        logger.info(f"   Tekst (pierwsze 200 znakÃ³w): {tekst[:200]}")
        
        # Split tekstu na linie z oznaczeniami i bez
        lines = tekst.split('\n')
        current_speaker = "Narrator"  # DomyÅ›lny mÃ³wca
        current_text = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # SprawdÅº czy linia zaczyna siÄ™ od oznaczenia mÃ³wcy
            match = re.match(r'^([A-ZÅÅšÅ»Å¹Ä†Åƒ][a-zÄ…Ä™Ã³Å‚Å›Å¼ÅºÄ‡Å„]+(?:\s+\[[MK]\])?):(.+)', line)
            
            if match:
                # Nowy mÃ³wca - zapisz poprzedni segment
                if current_text:
                    full_text = '\n'.join(current_text).strip()
                    if full_text:
                        voice_type = self._okresl_glos_cloud(current_speaker, plec_gracza)
                        logger.info(f"   â†’ Segment: speaker='{current_speaker}', voice={voice_type}, tekst_len={len(full_text)}")
                        segments.append((voice_type, full_text))
                
                # Nowy mÃ³wca
                current_speaker = match.group(1).strip()
                current_text = [match.group(2).strip()]
            else:
                # Kontynuacja tekstu poprzedniego mÃ³wcy lub narracja bez oznaczenia
                if not current_text:
                    # Tekst bez mÃ³wcy na poczÄ…tku - to narrator
                    current_speaker = "Narrator"
                current_text.append(line)
        
        # Zapisz ostatni segment
        if current_text:
            full_text = '\n'.join(current_text).strip()
            if full_text:
                voice_type = self._okresl_glos_cloud(current_speaker, plec_gracza)
                logger.info(f"   â†’ Segment: speaker='{current_speaker}', voice={voice_type}, tekst_len={len(full_text)}")
                segments.append((voice_type, full_text))
        
        logger.info(f"   Znaleziono {len(segments)} segmentÃ³w")
        
        return segments
    
    def _okresl_glos_cloud(self, speaker: str, plec_gracza: str) -> str:
        """OkreÅ›la typ gÅ‚osu dla Cloud TTS na podstawie mÃ³wcy"""
        speaker_lower = speaker.lower()
        
        print(f"ðŸ” CLOUD TTS _okresl_glos_cloud: speaker='{speaker}', speaker_lower='{speaker_lower}', plec_gracza='{plec_gracza}'")
        logger.info(f"ðŸ” CLOUD TTS _okresl_glos_cloud: speaker='{speaker}', speaker_lower='{speaker_lower}', plec_gracza='{plec_gracza}'")
        
        # OkreÅ›l typ gÅ‚osu
        if "narrator" in speaker_lower:
            voice_type = "narrator"
            print(f"  âœ… Match: NARRATOR â†’ narrator")
            logger.info(f"  â†’ NARRATOR â†’ narrator")
        elif "gracz" in speaker_lower:
            # UÅ¼yj pÅ‚ci gracza do wyboru gÅ‚osu
            voice_type = "gracz_k" if plec_gracza == "kobieta" else "gracz_m"
            print(f"  âœ… Match: GRACZ ({plec_gracza}) â†’ {voice_type}")
            logger.info(f"  â†’ GRACZ ({plec_gracza}) â†’ {voice_type}")
        elif "[k]" in speaker_lower:
            voice_type = "npc_k"
            print(f"  âœ… Match: [k] found â†’ npc_k")
            logger.info(f"  â†’ NPC [K] â†’ npc_k")
        elif "[m]" in speaker_lower:
            voice_type = "npc_m"
            print(f"  âœ… Match: [m] found â†’ npc_m")
            logger.info(f"  â†’ NPC [M] â†’ npc_m")
        else:
            # Inteligentne rozpoznawanie po imieniu
            zenskie_zakonczenia = ('a', 'na', 'wa', 'ka', 'ta')
            meskie_wyjatki = ('kuba', 'barnaba', 'kosma')
            
            imie_parts = speaker_lower.split()
            if len(imie_parts) > 0:
                pierwsze_slowo = imie_parts[0]
                print(f"  ðŸ” Fallback - sprawdzam imiÄ™ NPC: '{pierwsze_slowo}'")
                logger.info(f"  â†’ Sprawdzam imiÄ™ NPC: '{pierwsze_slowo}'")
                
                if pierwsze_slowo.endswith(zenskie_zakonczenia) and pierwsze_slowo not in meskie_wyjatki:
                    voice_type = "npc_k"
                    print(f"  âœ… KoÅ„cÃ³wka '{pierwsze_slowo[-2:]}' â†’ npc_k (KOBIETA)")
                    logger.info(f"  â†’ NPC Å»EÅƒSKI (koÅ„cÃ³wka '{pierwsze_slowo[-2:]}') â†’ npc_k")
                else:
                    voice_type = "npc_m"
                    print(f"  âœ… Brak Å¼eÅ„skiej koÅ„cÃ³wki â†’ npc_m (MÄ˜Å»CZYZNA)")
                    logger.info(f"  â†’ NPC MÄ˜SKI â†’ npc_m")
            else:
                # DomyÅ›lnie narrator
                voice_type = "narrator"
                print(f"  âš ï¸ Fallback â†’ narrator (brak imienia)")
                logger.info(f"  â†’ DOMYÅšLNY â†’ narrator")
        
        print(f"  ðŸŽ¯ FINAL RESULT: voice_type='{voice_type}'")
        logger.info(f"  ðŸŽ¯ FINAL: voice_type='{voice_type}'")
        return voice_type
    
    def _parsuj_dialogi(self, tekst: str, plec_gracza: str) -> list:
        """
        Parsuje tekst i zwraca listÄ™ (gÅ‚os, tekst).
        Format: MÃ³wca: tekst (gwiazdki ** sÄ… juÅ¼ usuniÄ™te przez game_master)
        """
        segments = []
        
        print(f"ðŸ” PIPER _parsuj_dialogi: zaczynamy parsowanie...")
        print(f"   Tekst (pierwsze 200 znakÃ³w): {tekst[:200]}")
        logger.info(f"ðŸ” PIPER _parsuj_dialogi: zaczynamy parsowanie...")
        logger.info(f"   Tekst (pierwsze 200 znakÃ³w): {tekst[:200]}")
        
        # Split tekstu na linie z oznaczeniami i bez
        lines = tekst.split('\n')
        current_speaker = "Narrator"  # DomyÅ›lny mÃ³wca
        current_text = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # SprawdÅº czy linia zaczyna siÄ™ od oznaczenia mÃ³wcy
            match = re.match(r'^([A-ZÅÅšÅ»Å¹Ä†Åƒ][a-zÄ…Ä™Ã³Å‚Å›Å¼ÅºÄ‡Å„]+(?:\s+\[[MK]\])?):(.+)', line)
            
            if match:
                # Nowy mÃ³wca - zapisz poprzedni segment
                if current_text:
                    full_text = '\n'.join(current_text).strip()
                    if full_text:
                        print(f"   â†’ Segment: speaker='{current_speaker}', tekst_len={len(full_text)}")
                        logger.info(f"   â†’ Segment: speaker='{current_speaker}', tekst_len={len(full_text)}")
                        voice = self._okresl_glos(current_speaker, plec_gracza)
                        segments.append((voice, full_text))
                
                # Nowy mÃ³wca
                current_speaker = match.group(1).strip()
                current_text = [match.group(2).strip()]
            else:
                # Kontynuacja tekstu poprzedniego mÃ³wcy lub narracja bez oznaczenia
                if not current_text:
                    # Tekst bez mÃ³wcy na poczÄ…tku - to narrator
                    current_speaker = "Narrator"
                current_text.append(line)
        
        # Zapisz ostatni segment
        if current_text:
            full_text = '\n'.join(current_text).strip()
            if full_text:
                print(f"   â†’ Segment: speaker='{current_speaker}', tekst_len={len(full_text)}")
                logger.info(f"   â†’ Segment: speaker='{current_speaker}', tekst_len={len(full_text)}")
                voice = self._okresl_glos(current_speaker, plec_gracza)
                segments.append((voice, full_text))
        
        print(f"   Znaleziono {len(segments)} segmentÃ³w")
        logger.info(f"   Znaleziono {len(segments)} segmentÃ³w")
        
        return segments
    
    def _okresl_glos(self, speaker: str, plec_gracza: str) -> str:
        """Dobiera gÅ‚os na podstawie mÃ³wiÄ…cego i pÅ‚ci"""
        speaker_lower = speaker.lower()
        
        print(f"ðŸ” DEBUG _okresl_glos: speaker='{speaker}', plec_gracza='{plec_gracza}'")
        logger.info(f"ðŸ” DEBUG _okresl_glos: speaker='{speaker}', plec_gracza='{plec_gracza}'")
        
        # Narrator - gÅ‚Ä™boki mÄ™ski gÅ‚os
        if 'narrator' in speaker_lower:
            logger.info(f"  â†’ NARRATOR â†’ jarvis")
            return 'jarvis'
        
        # Gracz - zaleÅ¼nie od pÅ‚ci
        if 'gracz' in speaker_lower:
            glos = 'zenski' if plec_gracza == 'kobieta' else 'meski'
            logger.info(f"  â†’ GRACZ ({plec_gracza}) â†’ {glos}")
            return glos
        
        # NPC - sprawdÅº oznaczenie [M]/[K] lub typowe mÄ™skie/Å¼eÅ„skie imiona
        if '[m]' in speaker_lower:
            logger.info(f"  â†’ NPC [M] â†’ darkman")
            return 'darkman'
        elif '[k]' in speaker_lower:
            logger.info(f"  â†’ NPC [K] â†’ justyna")
            return 'justyna'
        
        # Typowe Å¼eÅ„skie zakoÅ„czenia imion sÅ‚owiaÅ„skich
        zenskie_zakonczenia = ('a', 'na', 'wa', 'ka', 'ta')
        # WyÅ‚Ä…czenia - mÄ™skie imiona koÅ„czÄ…ce siÄ™ na 'a'
        meskie_wyjatki = ('kuba', 'barnaba', 'kosma')
        
        # SprawdÅº czy to NPC po imieniu
        imie_parts = speaker_lower.split()
        if len(imie_parts) > 0:
            pierwsze_slowo = imie_parts[0]
            logger.info(f"  â†’ Sprawdzam imiÄ™: '{pierwsze_slowo}'")
            # JeÅ›li to typowo Å¼eÅ„skie imiÄ™
            if pierwsze_slowo.endswith(zenskie_zakonczenia) and pierwsze_slowo not in meskie_wyjatki:
                logger.info(f"  â†’ NPC Å»EÅƒSKI (koÅ„cÃ³wka '{pierwsze_slowo[-2:]}') â†’ justyna")
                return 'justyna'
            # JeÅ›li to typowo mÄ™skie (lub nie pasuje do Å¼eÅ„skich)
            elif not pierwsze_slowo.endswith(zenskie_zakonczenia):
                logger.info(f"  â†’ NPC MÄ˜SKI (brak Å¼eÅ„skiej koÅ„cÃ³wki) â†’ darkman")
                return 'darkman'
        
        # DomyÅ›lnie narrator
        logger.info(f"  â†’ DOMYÅšLNY â†’ jarvis")
        return 'jarvis'
    
    def _sklej_audio(self, audio_files: list) -> Path:
        """Skleja wiele plikÃ³w WAV w jeden"""
        output_file = self.audio_dir / f"{uuid.uuid4().hex}.wav"
        
        try:
            # OtwÃ³rz wszystkie pliki i zbierz dane
            data = []
            params = None
            
            for audio_path in audio_files:
                with wave.open(str(audio_path), 'rb') as wf:
                    if params is None:
                        params = wf.getparams()
                    data.append(wf.readframes(wf.getnframes()))
            
            # Zapisz sklejony plik
            with wave.open(str(output_file), 'wb') as output:
                output.setparams(params)
                for d in data:
                    output.writeframes(d)
            
            # UsuÅ„ tymczasowe pliki
            for audio_path in audio_files:
                try:
                    audio_path.unlink()
                except:
                    pass
            
            return output_file
            
        except Exception as e:
            print(f"BÅ‚Ä…d sklejania audio: {e}")
            # ZwrÃ³Ä‡ pierwszy plik jako fallback
            return audio_files[0] if audio_files else None
